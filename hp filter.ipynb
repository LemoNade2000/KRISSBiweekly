{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.filters.hp_filter import hpfilter\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model._ridge import Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "from keras.metrics import mean_absolute_percentage_error, RootMeanSquaredError\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "import warnings\n",
    "from xgboost import XGBRegressor\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will explore the difference between applying regression model (Kernel ridge regression) using different sets of data : a raw data (closing price of stocks daily), and a preprocessed smoothed data (closing price of stocks w/ HP-Filter applied). For the sake of comparison, I will be using two different assets, which are TESLA and US Treasury bond. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = 250 # This parameter sets different number of days we are going to use for our time lag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply timelag to our data in order to generate more data from a single source. This technique is commonly used in time series analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def produceHP(ticker):\n",
    "    ticker = \"\\\\Data\\\\{}\".format(ticker) + \".csv\"\n",
    "    dir = os.getcwd() + ticker\n",
    "    data = pd.read_csv(dir)\n",
    "    data = data.set_index('Date')\n",
    "    data['preprice'] = data['Close'].T.shift(1)\n",
    "    data = data.dropna()\n",
    "    data['Close'] = (data['Close'] - data['preprice']) / data['Close']\n",
    "    cycle, trend = sm.tsa.filters.hpfilter(data['Close'], 10000000)\n",
    "    x = data.index\n",
    "    x = [dt.datetime.strptime(d, '%Y-%m-%d') for d in x]\n",
    "    y = trend\n",
    "    # plt.plot(x, y)\n",
    "    # y = data['Close']\n",
    "    # plt.plot(x, y)\n",
    "    # plt.show()\n",
    "    return (data, trend, cycle)\n",
    "\n",
    "produceHP(\"TSLA\")\n",
    "def reshape_data(df):\n",
    "    data_reshape = pd.concat([df['Close'].T.shift(i).to_frame().stack(dropna=False) for i in range(days) ], 1).dropna()\n",
    "    data_reshape.columns = pd.Index(range(days), name='timeLag')\n",
    "    return data_reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we apply HP-filter to a data and see what it does in order to understand it. Then, we apply time lag to the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, trend, cycle = produceHP(\"TSLA\")\n",
    "data_reshape = reshape_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a split method in order to set some of the data as test set, and some as training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data):\n",
    "    X = data[np.arange(1, days)]\n",
    "    y = data[0]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.25)\n",
    "    return (X_train, X_test, X_valid, y_train, y_test, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we apply time lag onto HP-Filter too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_HP_lag(data_reshape):\n",
    "    trend_data = pd.DataFrame()\n",
    "    # trend_data.columns = pd.Index(range(50), name='timeLag')\n",
    "    rows = []\n",
    "    for i in range(len(data_reshape)):\n",
    "        row = data_reshape.iloc[i]\n",
    "        cycle, trend = sm.tsa.filters.hpfilter(row[1:], 100000)\n",
    "        trend = pd.concat([cycle, trend], axis = 0)\n",
    "        trend.index = np.arange(1, len(cycle) * 2 + 1)\n",
    "        rows.append(pd.concat([pd.Series(row[0]), trend], axis = 0))\n",
    "    \n",
    "    trend_data = pd.DataFrame(rows)\n",
    "    trend_data.columns = pd.Index(range(days * 2 - 1), name='timeLag')\n",
    "    return trend_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we now have all data that we need for comparison, we run kernel-ridge regression to test how the model performs. We decided to use this model since it supports non-linearity of the data. Hyperparameter, also known as a regularization factor can be adjusted accordingly. If regularization term is 0, it becomes a traditional least-square problem, while higher regularization factor underfits the model. Thus, there are two hyperparameters in our model : number of days used for prediction, and regularization factor alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(data_reshape, reg):\n",
    "    sum = 0.0\n",
    "    for i in range(10):\n",
    "        X_train, X_test, X_valid, y_train, y_test, y_valid = split(data_reshape)\n",
    "        model = XGBRegressor()\n",
    "        model.fit(X_train, y_train, eval_set = [(X_valid, y_valid)], early_stopping_rounds=5)\n",
    "        prediction = model.predict(X_test)\n",
    "        m = RootMeanSquaredError()\n",
    "        m.update_state(y_test, prediction)\n",
    "        sum += m.result()\n",
    "    return sum.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = \"TSLA\"\n",
    "days = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(t, d, a):\n",
    "    ticker = t\n",
    "    days = d\n",
    "    data, trend, cycle = produceHP(ticker)\n",
    "    data_reshape = reshape_data(data)\n",
    "    trend_reshape = get_HP_lag(data_reshape)\n",
    "    print(trend_reshape)\n",
    "    return (test(data_reshape, a), test(trend_reshape, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timeLag       0         1         2         3         4         5         6    \\\n",
      "0       -0.003215  0.055703 -0.029111  0.096367 -0.080489  0.015597 -0.054085   \n",
      "1       -0.073133 -0.000436  0.055738 -0.029078  0.096398 -0.080459  0.015626   \n",
      "2       -0.032494 -0.064813  0.004716  0.060678 -0.024349  0.100917 -0.076147   \n",
      "3        0.054550 -0.021968 -0.063067  0.006390  0.062280 -0.022818  0.102379   \n",
      "4        0.051558  0.060527 -0.026779 -0.067680  0.001974  0.058060 -0.026844   \n",
      "..            ...       ...       ...       ...       ...       ...       ...   \n",
      "941      0.002464 -0.042974 -0.037456 -0.021844  0.003086  0.022364  0.002211   \n",
      "942      0.024493  0.007374 -0.043560 -0.038018 -0.022382  0.002572  0.021873   \n",
      "943      0.016921  0.027441  0.005193 -0.045651 -0.040020 -0.024295  0.000746   \n",
      "944     -0.073077  0.018553  0.025966  0.003779 -0.047005 -0.041314 -0.025529   \n",
      "945     -0.011159 -0.065836  0.023787  0.030984  0.008582 -0.042414 -0.036934   \n",
      "\n",
      "timeLag       7         8         9    ...       489       490       491  \\\n",
      "0       -0.010687 -0.032475 -0.048493  ...  0.002089  0.002318  0.002549   \n",
      "1       -0.054057 -0.010661 -0.032450  ...  0.002603  0.002875  0.003148   \n",
      "2        0.019733 -0.050152 -0.006953  ...  0.003024  0.003332  0.003644   \n",
      "3       -0.074755  0.021057 -0.048895  ...  0.002702  0.003006  0.003314   \n",
      "4        0.098543 -0.078403  0.017594  ... -0.000337 -0.000194 -0.000050   \n",
      "..            ...       ...       ...  ...       ...       ...       ...   \n",
      "941      0.006960  0.037521 -0.039494  ...  0.010212  0.010448  0.010681   \n",
      "942      0.001744  0.006516  0.037099  ...  0.010354  0.010616  0.010875   \n",
      "943      0.020135  0.000091  0.004946  ...  0.011119  0.011446  0.011769   \n",
      "944     -0.000429  0.019017 -0.000970  ...  0.011522  0.011895  0.012264   \n",
      "945     -0.021357  0.003538  0.022783  ...  0.011491  0.011887  0.012280   \n",
      "\n",
      "timeLag       492       493       494       495       496       497       498  \n",
      "0        0.002780  0.003010  0.003241  0.003471  0.003701  0.003930  0.004159  \n",
      "1        0.003422  0.003698  0.003975  0.004252  0.004529  0.004806  0.005082  \n",
      "2        0.003958  0.004275  0.004593  0.004912  0.005233  0.005554  0.005875  \n",
      "3        0.003625  0.003938  0.004254  0.004571  0.004889  0.005209  0.005528  \n",
      "4        0.000095  0.000240  0.000385  0.000529  0.000673  0.000818  0.000962  \n",
      "..            ...       ...       ...       ...       ...       ...       ...  \n",
      "941      0.010911  0.011138  0.011363  0.011588  0.011812  0.012035  0.012258  \n",
      "942      0.011130  0.011383  0.011634  0.011883  0.012132  0.012380  0.012628  \n",
      "943      0.012089  0.012407  0.012723  0.013038  0.013353  0.013667  0.013981  \n",
      "944      0.012631  0.012996  0.013359  0.013721  0.014083  0.014444  0.014805  \n",
      "945      0.012670  0.013058  0.013444  0.013829  0.014213  0.014596  0.014979  \n",
      "\n",
      "[946 rows x 499 columns]\n",
      "[16:27:28] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"eval_set\" } are not used.\n",
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Must have at least 1 validation dataset for early stopping.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26464\\245013794.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"TSLA\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m250\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26464\\3107265822.py\u001b[0m in \u001b[0;36mpipeline\u001b[1;34m(t, d, a)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtrend_reshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_HP_lag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_reshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrend_reshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_reshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrend_reshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26464\\2514796923.py\u001b[0m in \u001b[0;36mtest\u001b[1;34m(data_reshape, reg)\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_reshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRootMeanSquaredError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\Conda\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 620\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\Conda\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1049\u001b[0m                 \u001b[0mxgb_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m             )\n\u001b[1;32m-> 1051\u001b[1;33m             self._Booster = train(\n\u001b[0m\u001b[0;32m   1052\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m                 \u001b[0mtrain_dmatrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\Conda\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 620\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\Conda\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m         \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\Conda\\lib\\site-packages\\xgboost\\callback.py\u001b[0m in \u001b[0;36mafter_iteration\u001b[1;34m(self, model, epoch, dtrain, evals)\u001b[0m\n\u001b[0;32m    245\u001b[0m             \u001b[0mmetric_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmetric_score_str\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_history\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetric_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m         ret = any(c.after_iteration(model, epoch, self.history)\n\u001b[0m\u001b[0;32m    248\u001b[0m                   for c in self.callbacks)\n\u001b[0;32m    249\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\Conda\\lib\\site-packages\\xgboost\\callback.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    245\u001b[0m             \u001b[0mmetric_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmetric_score_str\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_history\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetric_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m         ret = any(c.after_iteration(model, epoch, self.history)\n\u001b[0m\u001b[0;32m    248\u001b[0m                   for c in self.callbacks)\n\u001b[0;32m    249\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\Conda\\lib\\site-packages\\xgboost\\callback.py\u001b[0m in \u001b[0;36mafter_iteration\u001b[1;34m(self, model, epoch, evals_log)\u001b[0m\n\u001b[0;32m    410\u001b[0m         \u001b[0mepoch\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstarting_round\u001b[0m  \u001b[1;31m# training continuation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Must have at least 1 validation dataset for early stopping.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 412\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevals_log\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    413\u001b[0m         \u001b[0mdata_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Must have at least 1 validation dataset for early stopping."
     ]
    }
   ],
   "source": [
    "pipeline(\"TSLA\", 250, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, RMSE for model using raw data was higher compared to its counterpart using smoothed data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timeLag       0         1         2         3         4         5         6    \\\n",
      "0       -0.018615  0.003414 -0.013842  0.022877 -0.010055  0.006533  0.009274   \n",
      "1       -0.009395 -0.011557  0.004333 -0.012962  0.023720 -0.009249  0.007302   \n",
      "2       -0.041895 -0.002005 -0.011398  0.004486 -0.012815  0.023860 -0.009116   \n",
      "3        0.039489 -0.031707  0.000516 -0.008981  0.006799 -0.010605  0.025969   \n",
      "4        0.008576  0.046135 -0.035374 -0.003000 -0.012347  0.003582 -0.013674   \n",
      "..            ...       ...       ...       ...       ...       ...       ...   \n",
      "941      0.046674 -0.014358  0.042317 -0.028158  0.012205  0.001859 -0.013064   \n",
      "942      0.021695  0.032314 -0.016927  0.039854 -0.030516  0.009953 -0.000291   \n",
      "943     -0.069906  0.006397  0.031805 -0.017415  0.039387 -0.030962  0.009527   \n",
      "944      0.011209 -0.079085  0.012685  0.037833 -0.011645  0.044901 -0.025700   \n",
      "945      0.014984  0.001718 -0.079222  0.012554  0.037707 -0.011765  0.044787   \n",
      "\n",
      "timeLag       7         8         9    ...       489       490       491  \\\n",
      "0       -0.011717 -0.006255 -0.006958  ...  0.004681  0.004788  0.004894   \n",
      "1        0.010006 -0.011021 -0.005594  ...  0.005239  0.005385  0.005530   \n",
      "2        0.007429  0.010127 -0.010906  ...  0.005304  0.005462  0.005620   \n",
      "3       -0.007107  0.009340  0.011941  ...  0.005016  0.005166  0.005316   \n",
      "4        0.023046 -0.009887  0.006700  ...  0.005110  0.005273  0.005438   \n",
      "..            ...       ...       ...  ...       ...       ...       ...   \n",
      "941      0.004015 -0.012203  0.008561  ... -0.000208 -0.000153 -0.000098   \n",
      "942     -0.015112  0.002068 -0.014052  ... -0.000482 -0.000440 -0.000397   \n",
      "943     -0.000696 -0.015497  0.001702  ... -0.000129 -0.000064  0.000002   \n",
      "944      0.014538  0.004070 -0.010973  ...  0.001565  0.001729  0.001897   \n",
      "945     -0.025809  0.014435  0.003971  ...  0.001494  0.001661  0.001830   \n",
      "\n",
      "timeLag       492       493       494       495       496       497       498  \n",
      "0        0.004999  0.005104  0.005208  0.005312  0.005415  0.005519  0.005621  \n",
      "1        0.005676  0.005822  0.005967  0.006113  0.006259  0.006405  0.006550  \n",
      "2        0.005778  0.005936  0.006095  0.006254  0.006413  0.006572  0.006731  \n",
      "3        0.005466  0.005616  0.005766  0.005916  0.006067  0.006218  0.006369  \n",
      "4        0.005602  0.005767  0.005932  0.006097  0.006263  0.006429  0.006596  \n",
      "..            ...       ...       ...       ...       ...       ...       ...  \n",
      "941     -0.000043  0.000010  0.000063  0.000115  0.000166  0.000218  0.000269  \n",
      "942     -0.000355 -0.000314 -0.000274 -0.000235 -0.000197 -0.000160 -0.000122  \n",
      "943      0.000068  0.000134  0.000200  0.000264  0.000328  0.000392  0.000455  \n",
      "944      0.002067  0.002239  0.002414  0.002589  0.002764  0.002940  0.003116  \n",
      "945      0.002003  0.002179  0.002357  0.002537  0.002717  0.002899  0.003080  \n",
      "\n",
      "[946 rows x 499 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.49230874, 0.45733306)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline(\"^TNX\", 250, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10)\n",
      "(50, 10)\n"
     ]
    }
   ],
   "source": [
    "d = np.arange(10, 251, 40)\n",
    "a = [0.1, 0.01, 1, 10]\n",
    "rawMin = (0, 0)\n",
    "trendMin = (0, 0)\n",
    "rawScore = 999999\n",
    "trendScore = 999999\n",
    "for day in d:\n",
    "    days = day\n",
    "    ticker = \"TSLA\"\n",
    "    data, trend, cycle = produceHP(ticker)\n",
    "    data_reshape = reshape_data(data)\n",
    "    trend_reshape = get_HP_lag(data_reshape)\n",
    "    for alpha in a:\n",
    "        raw = test(data_reshape, alpha)\n",
    "        raw = raw\n",
    "        trend = test(trend_reshape, alpha)\n",
    "        trend = trend\n",
    "        if raw < rawScore:\n",
    "            rawScore = raw\n",
    "            rawMin = (day, alpha)\n",
    "        if trend < trendScore:\n",
    "            trendScore = trend\n",
    "            trendMin = (day, alpha)\n",
    "print(rawMin)\n",
    "print(trendMin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39556122\n",
      "0.40308732\n"
     ]
    }
   ],
   "source": [
    "print(rawScore)\n",
    "print(trendScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10)\n",
      "(10, 0.1)\n"
     ]
    }
   ],
   "source": [
    "rawMin = (0, 0)\n",
    "trendMin = (0, 0)\n",
    "rawScore = 999999\n",
    "trendScore = 999999\n",
    "for day in d:\n",
    "    days = day\n",
    "    ticker = \"NVDA\"\n",
    "    data, trend, cycle = produceHP(ticker)\n",
    "    data_reshape = reshape_data(data)\n",
    "    trend_reshape = get_HP_lag(data_reshape)\n",
    "    for alpha in a:\n",
    "        raw = test(data_reshape, alpha)\n",
    "        raw = raw\n",
    "        trend = test(trend_reshape, alpha)\n",
    "        trend = trend\n",
    "        if raw < rawScore:\n",
    "            rawScore = raw\n",
    "            rawMin = (day, alpha)\n",
    "        if trend < trendScore:\n",
    "            trendScore = trend\n",
    "            trendMin = (day, alpha)\n",
    "print(rawMin)\n",
    "print(trendMin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32349828\n",
      "0.32211268\n"
     ]
    }
   ],
   "source": [
    "print(rawScore)\n",
    "print(trendScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 0.1)\n",
      "(10, 1)\n"
     ]
    }
   ],
   "source": [
    "rawMin = (0, 0)\n",
    "trendMin = (0, 0)\n",
    "rawScore = 999999\n",
    "trendScore = 999999\n",
    "for day in d:\n",
    "    days = day\n",
    "    ticker = \"^TNX\"\n",
    "    data, trend, cycle = produceHP(ticker)\n",
    "    data_reshape = reshape_data(data)\n",
    "    trend_reshape = get_HP_lag(data_reshape)\n",
    "    for alpha in a:\n",
    "        raw = test(data_reshape, alpha)\n",
    "        raw = raw\n",
    "        trend = test(trend_reshape, alpha)\n",
    "        trend = trend\n",
    "        if raw < rawScore:\n",
    "            rawScore = raw\n",
    "            rawMin = (day, alpha)\n",
    "        if trend < trendScore:\n",
    "            trendScore = trend\n",
    "            trendMin = (day, alpha)\n",
    "print(rawMin)\n",
    "print(trendMin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37151995\n",
      "0.3774387\n"
     ]
    }
   ],
   "source": [
    "print(rawScore)\n",
    "print(trendScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 1)\n",
      "(210, 10)\n",
      "0.324441\n",
      "0.3123093\n"
     ]
    }
   ],
   "source": [
    "rawMin = (0, 0)\n",
    "trendMin = (0, 0)\n",
    "rawScore = 999999\n",
    "trendScore = 999999\n",
    "for day in d:\n",
    "    days = day\n",
    "    ticker = \"TWTR\"\n",
    "    data, trend, cycle = produceHP(ticker)\n",
    "    data_reshape = reshape_data(data)\n",
    "    trend_reshape = get_HP_lag(data_reshape)\n",
    "    for alpha in a:\n",
    "        raw = test(data_reshape, alpha)\n",
    "        raw = raw\n",
    "        trend = test(trend_reshape, alpha)\n",
    "        trend = trend\n",
    "        if raw < rawScore:\n",
    "            rawScore = raw\n",
    "            rawMin = (day, alpha)\n",
    "        if trend < trendScore:\n",
    "            trendScore = trend\n",
    "            trendMin = (day, alpha)\n",
    "print(rawMin)\n",
    "print(trendMin)\n",
    "print(rawScore)\n",
    "print(trendScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 0.1)\n",
      "(10, 0.01)\n",
      "0.31740874\n",
      "0.32639754\n"
     ]
    }
   ],
   "source": [
    "rawMin = (0, 0)\n",
    "trendMin = (0, 0)\n",
    "rawScore = 999999\n",
    "trendScore = 999999\n",
    "for day in d:\n",
    "    days = day\n",
    "    ticker = \"AXON\"\n",
    "    data, trend, cycle = produceHP(ticker)\n",
    "    data_reshape = reshape_data(data)\n",
    "    trend_reshape = get_HP_lag(data_reshape)\n",
    "    for alpha in a:\n",
    "        raw = test(data_reshape, alpha)\n",
    "        raw = raw\n",
    "        trend = test(trend_reshape, alpha)\n",
    "        trend = trend\n",
    "        if raw < rawScore:\n",
    "            rawScore = raw\n",
    "            rawMin = (day, alpha)\n",
    "        if trend < trendScore:\n",
    "            trendScore = trend\n",
    "            trendMin = (day, alpha)\n",
    "print(rawMin)\n",
    "print(trendMin)\n",
    "print(rawScore) \n",
    "print(trendScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 10)\n",
      "(10, 0.1)\n",
      "0.25987822\n",
      "0.2543211\n"
     ]
    }
   ],
   "source": [
    "rawMin = (0, 0)\n",
    "trendMin = (0, 0)\n",
    "rawScore = 999999\n",
    "trendScore = 999999\n",
    "for day in d:\n",
    "    days = day\n",
    "    ticker = \"FDP\"\n",
    "    data, trend, cycle = produceHP(ticker)\n",
    "    data_reshape = reshape_data(data)\n",
    "    trend_reshape = get_HP_lag(data_reshape)\n",
    "    for alpha in a:\n",
    "        raw = test(data_reshape, alpha)\n",
    "        raw = raw\n",
    "        trend = test(trend_reshape, alpha)\n",
    "        trend = trend\n",
    "        if raw < rawScore:\n",
    "            rawScore = raw\n",
    "            rawMin = (day, alpha)\n",
    "        if trend < trendScore:\n",
    "            trendScore = trend\n",
    "            trendMin = (day, alpha)\n",
    "print(rawMin)\n",
    "print(trendMin)\n",
    "print(rawScore) \n",
    "print(trendScore)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2cdd6f69fc207ea59adbf85df52271823ef95583e4ba7a186f1887986724f65a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
